Para analizar la calidad del algoritmo realizamos dos tipos diferentes de benchmark, uno que cuantifica la dispersión
media de distintas ejecuciones con distintas semillas para cada algoritmo y otro que estima después de un número
determinado de ejecuciones el tiempo de ejecución medio de cada algoritmo para cada dataset. Cuanto más se aproxime
a cero la dispersión mejor será el algoritmo. A iguales dispersiones consideraremos que un algoritmo es mejor que otro
si el tiempo de ejecución es significativamente menor.

Para el caso de los algoritmos genéticos, a diferencia de para los casos de los algoritmos Greedy y BL, recogeremos 
por cada fichero de benchmark la solución que nos proporcione el algoritmo en cuestión, para una única semilla. Procedemos
de igual forma para el caso de los algoritmos meméticos.

\begin{minipage}{\textwidth}
    \section{Procedimiento para la obtención de resultados}
    
    Los resultados disponibles en los cuadros de esta sección han sido resultado de distintas ejecuciones.
    
    Para obtener la dispersión hemos ejecutado el algoritmo para cada dataset para 5 semillas distintas disponibles
    en el script lanzador. Cada fila de los cuadros 3 y 4 corresponde a la dispersión media de los 5 resultados de cada
    una de estas ejecuciones (para los algoritmos que corresponda)
    
    Por otra parte, para obtener el tiempo medio de ejecución para fila de las tablas hemos ejecutado cada dataset
    para 5 semillas unas 50 veces en invocaciones diferentes y obtenido la media de los resultados del tiempo de estas
    $ 50 \cdot 5 $ ejecuciones (para los algoritmos que corresponda)
    
    Por último hemos calculado la desviación media de las soluciones para cada tabla como la suma de las desviaciones
    entre el número de casos, símil para el caso del cálculo del tiempo medio. La desviación la hemos calculado como la
    diferencia entre el coste en dispersión de nuestro algoritmo y el coste de nuestra referencia.
    
\end{minipage}

\input{resources/tabla_medias.tex}

\section{Análisis de los datos obtenidos}

Una vez extraidos los datos observamos cómo los algoritmos que implementamos nos ofrecen
soluciones sustancialmente diferentes según las semillas que empleamos, especialmente en
aquellos en los que parten de una única solución generada aleatoriamente. Parece que existe
cierta correlación entre una exploración más amplia del espacio de soluciones y
la obtención de mejores resultados.

\begin{figure}[H]
    \centering
    \includegraphics[keepaspectratio,width=\textwidth]{box_and_whisker_dispersion_media_dataset_y_tipo_algoritmo.png}
    \caption{Dispersión media por dataset y por tipo de algoritmo. Podemos observar que hay una alta desviación típica del coste de las soluciones.
    Podemos ver que una peor media de resultados en las ejecuciones no implica una peor mediana, y una peor mediana no implica un intervalo del percentil 25 al 75 peor.
    Destacamos también la correlación entre medianas dentro de un mismo tipo de algoritmo.}
\end{figure}

Para aumentar el espacio en el espacio de soluciones del conjunto de soluciones consideradas por los algoritmos Greedy y de Búsqueda Local y no quedar
así atrapados en óptimos locales utilizando estrategias de BL podríamos probar variantes como la Búsqueda Local Estocástica, Búsqueda Local por Primer Mejor Aleatorio, Búsqueda Local
con Reinicio Aleatorio u otras técnicas más avanzadas como el Enfriamiento Simulado o búsqueda \textit{Local Beam} entre otros.\cite[Sección 4.1]{russell2020artificial}

Probamos con las técnicas Búsqueda Local con Reinicio Aleatorio y Búsqueda Reiterada por BL y ES.
Podemos observar cómo, aun teniendo como base una búsqueda local, las soluciones obtenidas son significativamente mejores, observando de nuevo como destacábamos anteriormente
correlación entre una mayor exploración del espacio de soluciones y mejores soluciones.
Sin embargo esto no ocurre así para las ejecuciones del algoritmo de Enfriamiento Simulado. Podemos ver que ofrece soluciones un tanto mejores que una búsqueda local, pero bastante
peores que estos. Haciendo pruebas vemos cómo la función de aceptación probabilística
es significativamente determinante en los resultados finales obtenidos. Sospechamos que el no ofrecer mejores soluciones
es causa del operador de mutación del algoritmo, que no produce soluciones suficientemente diversas. Sin embargo no tenemos certeza en la causalidad,
sólo en los resultados obtenidos.

Otra opción para aumentar el espacio es la de usar algoritmos genéticos. Podemos ver que ofrecen unos muy buenos resultados, gracias a que no sólo van saltando más por el espacio de soluciones
sino que además van conservando las partes de las soluciones más prometedoras, alejándolos de una simple búsqueda aleatoria. Podemos ver cómo para el problema del MDD los modelos
estacionarios dan mejores soluciones que los generacionales. Esto se puede deber a que los generacionales sustituyen completamente la población original, mientras que los estacionarios
únicamente inserta las nuevas soluciones en la población inicial si estas son mejores, conservando más información acerca de las soluciones más prometedoras y no cayendo tanto en la aleatoriedad.

De igual forma podemos destacar cómo el operador de cruce uniforme ofrece mejores resultados que el de posición. Esto se debe a que ambos cruces, aunque mantienen la intersección de genes,
aleatorizan los genes que quedan por escoger. Sin embargo el cruce uniforme, al reparar la solución, va buscando y eliminando los genes que más le convenga, aplicando un esquema Greedy, que
seguramente ayudará a obtener soluciones con mejor fitness.

En nuestras ejecuciones los algoritmos meméticos, aunque mejores que una búsqueda local, dan peor rendimiento que el resto de algoritmos genéticos.
En este, cuanto más peso le damos al paso genético y cuanto más fuerte sea el elitismo, da mejores resultados.

\subsection{Conclusiones}

En el problema del MDD, para nuestras implementaciones de los algoritmos de búsqueda por trayectorias y de búsqueda por
poblaciones, comprobamos que los más efectivos son los genéticos AGE, meméticos, búsquedas reiteradas y búsquedas con
reinicio aleatorio. Es decir, existe una correlación entre aquellos que combinan una exploración del espacio de soluciones
más o menos amplio pero optimizando las soluciones por medio de búsquedas locales o parecidos y un mejor resultado en las
soluciones que obtenemos. Obtenemos mejores medias que otros métodos, como el acercamiento greedy, búsquedas locales y genéticos AGG.

\input{resources/tabla_ejecuciones_greedy.tex}
\input{resources/tabla_ejecuciones_localsearchbestfirst.tex}
\input{resources/tabla_ejecuciones_localsearch.tex}
\input{resources/tabla_ejecuciones_agg_uniforme.tex}
\input{resources/tabla_ejecuciones_agg_posicion.tex}
\input{resources/tabla_ejecuciones_age_uniforme.tex}
\input{resources/tabla_ejecuciones_age_posicion.tex}
\input{resources/tabla_ejecuciones_memetico_10_1.0.tex}
\input{resources/tabla_ejecuciones_memetico_10_0.1.tex}
\input{resources/tabla_ejecuciones_memetico_10_0.1best.tex}
\input{resources/tabla_ejecuciones_enfriamiento_simulado.tex}
\input{resources/tabla_ejecuciones_bmb.tex}
\input{resources/tabla_ejecuciones_ils.tex}
\input{resources/tabla_ejecuciones_ils_es.tex}